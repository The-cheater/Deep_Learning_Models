{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-cheater/Deep_Learning_Models/blob/main/ideal_sir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1Ô∏è‚É£ Google Drive & Extraction\n",
        "# ===========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Unzip datasets\n",
        "def unzip_dataset(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "unzip_dataset('/content/drive/MyDrive/dataset/GAF_Images.zip', '/content/GAF_Images')\n",
        "unzip_dataset('/content/drive/MyDrive/dataset/MTF_Images.zip', '/content/MTF_Images')"
      ],
      "metadata": {
        "id": "bFBeQNiKLxOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2Ô∏è‚É£ Imports and Setup\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "pDgGU_xwL4Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3Ô∏è‚É£ Optimized PairedDataset\n",
        "# ===========================\n",
        "class PairedDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, gaf_dir, mtf_dir, batch_size=16, img_size=(224,224), shuffle=True):\n",
        "        self.gaf_paths, self.mtf_paths, self.labels = self._load_pairs(gaf_dir, mtf_dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def _load_pairs(self, gaf_dir, mtf_dir):\n",
        "        gaf_paths, mtf_paths, labels = [], [], []\n",
        "        for root, _, files in os.walk(gaf_dir):\n",
        "            for fname in files:\n",
        "                if fname.endswith('_gaf.png'):\n",
        "                    gaf_path = os.path.join(root, fname)\n",
        "                    mtf_path = gaf_path.replace('GAF_Images', 'MTF_Images').replace('_gaf.png', '_mtf.png')\n",
        "                    if os.path.exists(mtf_path):\n",
        "                        gaf_paths.append(gaf_path)\n",
        "                        mtf_paths.append(mtf_path)\n",
        "                        labels.append(0 if '/EL/' in gaf_path else 1 if '/PD/' in gaf_path else 2)\n",
        "        return gaf_paths, mtf_paths, np.array(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        gaf_batch = [self._load_image(self.gaf_paths[i]) for i in batch_indices]\n",
        "        mtf_batch = [self._load_image(self.mtf_paths[i]) for i in batch_indices]\n",
        "        # Change the return type for the inputs from a list to a tuple\n",
        "        return (np.array(gaf_batch), np.array(mtf_batch)), self.labels[batch_indices]\n",
        "\n",
        "    def _load_image(self, path):\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.image.decode_png(img, channels=3)\n",
        "        img = tf.image.resize(img, self.img_size)\n",
        "        img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "        return img\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.labels))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "AVmR0neeL80J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4Ô∏è‚É£ TensorFlow Model Definition\n",
        "# ===========================\n",
        "def conv_block(x, filters, n_convs, name):\n",
        "    for i in range(n_convs):\n",
        "        x = layers.Conv2D(filters, 3, padding='same', name=f'{name}_conv{i+1}')(x)\n",
        "        x = layers.BatchNormalization(name=f'{name}_bn{i+1}')(x)\n",
        "        x = layers.ReLU(name=f'{name}_relu{i+1}')(x)\n",
        "    return x\n",
        "\n",
        "def create_l3_fusion_model(input_shape=(224,224,3), num_classes=3):\n",
        "    # Branch 1 (GAF)\n",
        "    input_gaf = layers.Input(shape=input_shape, name='gaf_input')\n",
        "    x1 = conv_block(input_gaf, 64, 2, 'branch1_conv1')\n",
        "    x1 = layers.MaxPool2D(2, 2, name='branch1_pool1')(x1)\n",
        "    x1 = conv_block(x1, 128, 2, 'branch1_conv2')\n",
        "    x1 = layers.MaxPool2D(2, 2, name='branch1_pool2')(x1)\n",
        "    x1 = conv_block(x1, 256, 3, 'branch1_conv3')\n",
        "    branch1_out = layers.MaxPool2D(2, 2, name='branch1_pool3')(x1)\n",
        "\n",
        "    # Branch 2 (MTF)\n",
        "    input_mtf = layers.Input(shape=input_shape, name='mtf_input')\n",
        "    x2 = conv_block(input_mtf, 64, 2, 'branch2_conv1')\n",
        "    x2 = layers.MaxPool2D(2, 2, name='branch2_pool1')(x2)\n",
        "    x2 = conv_block(x2, 128, 2, 'branch2_conv2')\n",
        "    x2 = layers.MaxPool2D(2, 2, name='branch2_pool2')(x2)\n",
        "    x2 = conv_block(x2, 256, 3, 'branch2_conv3')\n",
        "    branch2_out = layers.MaxPool2D(2, 2, name='branch2_pool3')(x2)\n",
        "\n",
        "    # Fusion\n",
        "    fused = layers.Concatenate(axis=-1)([\n",
        "        layers.Conv2D(256, 3, padding='same')(branch1_out),\n",
        "        layers.Conv2D(256, 3, padding='same')(branch2_out)\n",
        "    ])\n",
        "\n",
        "    # Common trunk\n",
        "    x = conv_block(fused, 512, 3, 'fusion_conv4')\n",
        "    x = layers.MaxPool2D(2, 2, name='pool4')(x)\n",
        "    x = conv_block(x, 512, 3, 'conv5')\n",
        "    x = layers.MaxPool2D(2, 2, name='pool5')(x)\n",
        "\n",
        "    # Classification head\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(4096, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(4096, activation='relu')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs=[input_gaf, input_mtf], outputs=outputs)"
      ],
      "metadata": {
        "id": "0mMJ8k2EMAvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5Ô∏è‚É£ Data Preparation\n",
        "# ===========================\n",
        "train_gen = PairedDataGenerator(\n",
        "    '/content/GAF_Images/GAF_Images_train',\n",
        "    '/content/MTF_Images/MTF_Images_train',\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = PairedDataGenerator(\n",
        "    '/content/GAF_Images/GAF_Images_train',\n",
        "    '/content/MTF_Images/MTF_Images_train',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "dO4b5AHAMFs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import datetime\n",
        "\n",
        "# ===========================\n",
        "# üìå Custom Callback for Clean Summary After Each Epoch\n",
        "# ===========================\n",
        "class ClearLogger(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        print(\"\\nüìä Epoch {:02d} Summary ‚Äî\".format(epoch + 1))\n",
        "        print(\"   üîπ Loss          : {:.4f}\".format(logs.get('loss', 0)))\n",
        "        print(\"   üîπ Accuracy      : {:.4f}\".format(logs.get('accuracy', 0)))\n",
        "        print(\"   üîπ Val Loss      : {:.4f}\".format(logs.get('val_loss', 0)))\n",
        "        print(\"   üîπ Val Accuracy  : {:.4f}\".format(logs.get('val_accuracy', 0)))\n",
        "        print(\"   üïê Time          : {}\".format(datetime.datetime.now().strftime(\"%H:%M:%S\")))\n",
        "\n",
        "# ===========================\n",
        "# 6Ô∏è‚É£ Model and Training Setup\n",
        "# ===========================\n",
        "model = create_l3_fusion_model()\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True, verbose=1),\n",
        "    ClearLogger()\n",
        "]\n",
        "\n",
        "# ===========================\n",
        "# 7Ô∏è‚É£ Training Execution\n",
        "# ===========================\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1  # üëà Keep this to get Keras' progress bar per epoch\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RmV7LHKMLp1",
        "outputId": "6acc1063-aa70-46e8-e709-78ef68524e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m239/252\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4993 - loss: 1.0279"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 8Ô∏è‚É£ Visualization\n",
        "# ===========================\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Val')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Val')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# ===========================\n",
        "# 9Ô∏è‚É£ Evaluation\n",
        "# ===========================\n",
        "test_gen = PairedDataGenerator(\n",
        "    '/content/GAF_Images/GAF_Images_test',\n",
        "    '/content/MTF_Images/MTF_Images_test',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(f\"‚úÖ Final Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "5o8TWLz3MRdm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}