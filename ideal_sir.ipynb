{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DQ_uSP9LD7GisuQEK3F8r4fdGmVxw-FK",
      "authorship_tag": "ABX9TyPYXe54g2MhyxoFPoywnwdT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-cheater/Deep_Learning_Models/blob/main/ideal_sir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1️⃣ Google Drive & Extraction\n",
        "# ===========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Unzip datasets\n",
        "def unzip_dataset(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "unzip_dataset('/content/drive/MyDrive/dataset/GAF_Images.zip', '/content/GAF_Images')\n",
        "unzip_dataset('/content/drive/MyDrive/dataset/MTF_Images.zip', '/content/MTF_Images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFBeQNiKLxOs",
        "outputId": "32f8187b-c1f7-434e-a9d1-d379ce6ceeae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2️⃣ Imports and Setup\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "pDgGU_xwL4Fg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3️⃣ Optimized PairedDataset\n",
        "# ===========================\n",
        "class PairedDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, gaf_dir, mtf_dir, batch_size=16, img_size=(224,224), shuffle=True):\n",
        "        self.gaf_paths, self.mtf_paths, self.labels = self._load_pairs(gaf_dir, mtf_dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def _load_pairs(self, gaf_dir, mtf_dir):\n",
        "        gaf_paths, mtf_paths, labels = [], [], []\n",
        "        for root, _, files in os.walk(gaf_dir):\n",
        "            for fname in files:\n",
        "                if fname.endswith('_gaf.png'):\n",
        "                    gaf_path = os.path.join(root, fname)\n",
        "                    mtf_path = gaf_path.replace('GAF_Images', 'MTF_Images').replace('_gaf.png', '_mtf.png')\n",
        "                    if os.path.exists(mtf_path):\n",
        "                        gaf_paths.append(gaf_path)\n",
        "                        mtf_paths.append(mtf_path)\n",
        "                        labels.append(0 if '/EL/' in gaf_path else 1 if '/PD/' in gaf_path else 2)\n",
        "        return gaf_paths, mtf_paths, np.array(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        gaf_batch = [self._load_image(self.gaf_paths[i]) for i in batch_indices]\n",
        "        mtf_batch = [self._load_image(self.mtf_paths[i]) for i in batch_indices]\n",
        "        # Change the return type for the inputs from a list to a tuple\n",
        "        return (np.array(gaf_batch), np.array(mtf_batch)), self.labels[batch_indices]\n",
        "\n",
        "    def _load_image(self, path):\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.image.decode_png(img, channels=3)\n",
        "        img = tf.image.resize(img, self.img_size)\n",
        "        img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "        return img\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.labels))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "AVmR0neeL80J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4️⃣ TensorFlow Model Definition\n",
        "# ===========================\n",
        "def conv_block(x, filters, n_convs, name):\n",
        "    for i in range(n_convs):\n",
        "        x = layers.Conv2D(filters, 3, padding='same', name=f'{name}_conv{i+1}')(x)\n",
        "        x = layers.BatchNormalization(name=f'{name}_bn{i+1}')(x)\n",
        "        x = layers.ReLU(name=f'{name}_relu{i+1}')(x)\n",
        "    return x\n",
        "\n",
        "def create_l3_fusion_model(input_shape=(224,224,3), num_classes=3):\n",
        "    # Branch 1 (GAF)\n",
        "    input_gaf = layers.Input(shape=input_shape, name='gaf_input')\n",
        "    x1 = conv_block(input_gaf, 64, 2, 'branch1_conv1')\n",
        "    x1 = layers.MaxPool2D(2, 2, name='branch1_pool1')(x1)\n",
        "    x1 = conv_block(x1, 128, 2, 'branch1_conv2')\n",
        "    x1 = layers.MaxPool2D(2, 2, name='branch1_pool2')(x1)\n",
        "    x1 = conv_block(x1, 256, 3, 'branch1_conv3')\n",
        "    branch1_out = layers.MaxPool2D(2, 2, name='branch1_pool3')(x1)\n",
        "\n",
        "    # Branch 2 (MTF)\n",
        "    input_mtf = layers.Input(shape=input_shape, name='mtf_input')\n",
        "    x2 = conv_block(input_mtf, 64, 2, 'branch2_conv1')\n",
        "    x2 = layers.MaxPool2D(2, 2, name='branch2_pool1')(x2)\n",
        "    x2 = conv_block(x2, 128, 2, 'branch2_conv2')\n",
        "    x2 = layers.MaxPool2D(2, 2, name='branch2_pool2')(x2)\n",
        "    x2 = conv_block(x2, 256, 3, 'branch2_conv3')\n",
        "    branch2_out = layers.MaxPool2D(2, 2, name='branch2_pool3')(x2)\n",
        "\n",
        "    # Fusion\n",
        "    fused = layers.Concatenate(axis=-1)([\n",
        "        layers.Conv2D(256, 3, padding='same')(branch1_out),\n",
        "        layers.Conv2D(256, 3, padding='same')(branch2_out)\n",
        "    ])\n",
        "\n",
        "    # Common trunk\n",
        "    x = conv_block(fused, 512, 3, 'fusion_conv4')\n",
        "    x = layers.MaxPool2D(2, 2, name='pool4')(x)\n",
        "    x = conv_block(x, 512, 3, 'conv5')\n",
        "    x = layers.MaxPool2D(2, 2, name='pool5')(x)\n",
        "\n",
        "    # Classification head\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(4096, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(4096, activation='relu')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs=[input_gaf, input_mtf], outputs=outputs)"
      ],
      "metadata": {
        "id": "0mMJ8k2EMAvp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5️⃣ Data Preparation\n",
        "# ===========================\n",
        "train_gen = PairedDataGenerator(\n",
        "    '/content/GAF_Images/GAF_Images_train',\n",
        "    '/content/MTF_Images/MTF_Images_train',\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = PairedDataGenerator(\n",
        "    '/content/GAF_Images/GAF_Images_train',\n",
        "    '/content/MTF_Images/MTF_Images_train',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "dO4b5AHAMFs6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 6️⃣ Model and Training Setup\n",
        "# ===========================\n",
        "model = create_l3_fusion_model()\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "]\n",
        "# ===========================\n",
        "# 7️⃣ Training Execution\n",
        "# ===========================\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RmV7LHKMLp1",
        "outputId": "76e75b15-d813-4d5f-94ad-cff3b5c720b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5208 - loss: 0.9937"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 2s/step - accuracy: 0.5209 - loss: 0.9935 - val_accuracy: 0.5690 - val_loss: 0.9856 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5707 - loss: 0.8837"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 2s/step - accuracy: 0.5708 - loss: 0.8836 - val_accuracy: 0.5355 - val_loss: 0.9608 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 2s/step - accuracy: 0.6251 - loss: 0.8255 - val_accuracy: 0.5763 - val_loss: 1.1086 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6621 - loss: 0.7645"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 2s/step - accuracy: 0.6620 - loss: 0.7645 - val_accuracy: 0.5943 - val_loss: 0.9291 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 2s/step - accuracy: 0.6947 - loss: 0.6795 - val_accuracy: 0.5127 - val_loss: 1.1210 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7385 - loss: 0.6076"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 2s/step - accuracy: 0.7385 - loss: 0.6076 - val_accuracy: 0.6458 - val_loss: 0.8960 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7847 - loss: 0.5083"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 2s/step - accuracy: 0.7847 - loss: 0.5083 - val_accuracy: 0.6593 - val_loss: 0.7040 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8181 - loss: 0.4305"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 2s/step - accuracy: 0.8181 - loss: 0.4305 - val_accuracy: 0.7981 - val_loss: 0.5470 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8450 - loss: 0.3838"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 2s/step - accuracy: 0.8451 - loss: 0.3837 - val_accuracy: 0.8279 - val_loss: 0.4235 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8980 - loss: 0.2651"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 2s/step - accuracy: 0.8980 - loss: 0.2651 - val_accuracy: 0.9327 - val_loss: 0.1741 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 2s/step - accuracy: 0.9208 - loss: 0.1968 - val_accuracy: 0.6853 - val_loss: 0.7754 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 2s/step - accuracy: 0.9450 - loss: 0.1503 - val_accuracy: 0.6507 - val_loss: 1.3524 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 2s/step - accuracy: 0.9542 - loss: 0.1255 - val_accuracy: 0.9235 - val_loss: 0.2086 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 2s/step - accuracy: 0.9760 - loss: 0.0640 - val_accuracy: 0.8303 - val_loss: 0.4045 - learning_rate: 5.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9780 - loss: 0.0678"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 2s/step - accuracy: 0.9780 - loss: 0.0678 - val_accuracy: 0.9937 - val_loss: 0.0211 - learning_rate: 5.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0238 - val_accuracy: 0.9386 - val_loss: 0.1688 - learning_rate: 5.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 2s/step - accuracy: 0.9823 - loss: 0.0529 - val_accuracy: 0.9917 - val_loss: 0.0251 - learning_rate: 5.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 2s/step - accuracy: 0.9910 - loss: 0.0255 - val_accuracy: 0.9917 - val_loss: 0.0261 - learning_rate: 5.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9963 - loss: 0.0127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 2s/step - accuracy: 0.9963 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 9.5035e-04 - learning_rate: 2.5000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m170/252\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 1s/step - accuracy: 0.9892 - loss: 0.0366"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 8️⃣ Visualization\n",
        "# ===========================\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Val')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Val')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# ===========================\n",
        "# 9️⃣ Evaluation\n",
        "# ===========================\n",
        "test_gen = PairedDataGenerator(\n",
        "    '/content/GAF_Images/GAF_Images_test',\n",
        "    '/content/MTF_Images/MTF_Images_test',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(f\"✅ Final Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "5o8TWLz3MRdm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}